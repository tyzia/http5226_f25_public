Recap from Week 3



Scientific notation

A short way to represent
a very large or a very small number

Example

8,000,000,000 -> 8e9
0.000000000012 ->1.2e-11



Number types

1) int

- represents whole numbers
- size 32 bits
- 4 billion
- used for counters, indexes

int numberOfUsers = 243;

2) float

- approximate numbers with floating point
- size 32 bits
- fast & memory-efficient
- limited precision (~6-9 decimal digits).

Used when performance and memory
are critical:

- science
- graphics programming
- older games

To declare a float - suffix a number with 'f'.

float temperature = 37.6f;

If you miss 'f' you would get an error:

float temperature = 37.6; // double -> error


3) double

- more precise than float
- still approximate
- size 64 bits
- default for numbers in C#

Used for most general-purpose calculations
involving fractions.

To declare a double - suffix a number with 'd' (optional)

double distance = 1234.567;
double speedOfLight = 2.9e8;
double preciseValue = 1.234d;

4) decimal

- high-precision
- size 128 bits
- doesn't have rounding errors
- significantly slower

Use for financial calculations.

To declare a decimal - suffix number with 'm'.

decimal price = 29.99m;

Digit separators

You can use '_' to make numbers more readable:

decimal bankBalance = 1000000.50M;
decimal bankBalance = 1_000_000.50M;




Order of precedence

1) Increment & decrement -> a++, b--
2) Positive and negative -> -a
3) Multiplication, division, modulus -> a * b, a / b, a % b
4) Addition & subtraction -> a + b, a - b

To override order of precedence - use ()

a + b * c
(a + b) * c

Increment/decrement can be used as

- prefix -> ++a
- postfix -> a++

Prefix - variable is incremented and then
result is assigned.

int a = 0;
int b = ++a;

Result:
a = 1, b = 1

Postfix - the result is assigned and then
variable is incremented.

int a = 0;
int b = a++;

Result:
a = 1, b = 0



Type conversions (casting)

- Implicit (done automatically by C#)
- Explicit (you code it)

Implicit = from less precise type
to a more precise.

byte -> int

byte (0 to 255) <- less precise than int
int (-2 bn to +2 bn) <- more precise than byte

float -> double -> decimal

Example

double grade = 93f;


Implicit conversion from more precise to
less precise will not work:

int grade = 93.75; // error

Use explicit cast:

int grade = (int) 93.75; // 93

decimal result = (decimal) 10 / 3; // 3.33(3)

If you cast the result of division,
you may get unexpected results:

decimal result = (decimal) (10 / 3); // 3.00

